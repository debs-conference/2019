<!DOCTYPE html>
<html lang="zxx" class="no-js">
<head>
    <!-- Mobile Specific Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Favicon-->
    <link rel="shortcut icon" href="img/fav.png">
    <!-- Author Meta -->
    <meta name="author" content="codepixer">
    <!-- Meta Description -->
    <meta name="description" content="">
    <!-- Meta Keyword -->
    <meta name="keywords" content="">
    <!-- meta character set -->
    <meta charset="UTF-8">
    <!-- Site Title -->
    <title>DEBS 2019</title>

    <link href="https://fonts.googleapis.com/css?family=Poppins:100,200,400,300,500,600,700" rel="stylesheet">
    <!--
    CSS
    ============================================= -->
    <link rel="stylesheet" href="css/linearicons.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/bootstrap.css">
    <link rel="stylesheet" href="css/magnific-popup.css">
    <link rel="stylesheet" href="css/nice-select.css">
    <link rel="stylesheet" href="css/animate.min.css">
    <link rel="stylesheet" href="css/owl.carousel.css">
    <link rel="stylesheet" href="css/main.css">
</head>
<body>

<header id="header" id="home">
    <div class="container">
        <div class="row align-items-center justify-content-between d-flex">
            <div id="logo">
                <a href="index.html"><img src="img/DEBS2019.png" alt="" title="" style="width:194px;"/></a>
            </div>
            <nav id="nav-menu-container">
                <ul class="nav-menu">
                    <li class="menu-active"><a href="index.html">Home</a></li>
                    <li class="menu-active"><a href="about.html">About</a></li>
                    <li class="menu-has-children"><a href="">Calls</a>
                        <ul>
                            <li><a href="Calls/Call_for_Research_Papers.html">Call for Research Papers</a></li>
                            <li><a href="Calls/Call_for_Industry_Papers.html">Call for Industry Papers</a></li>
                            <li><a href="Calls/Call_for_Tutorials.html">Call for Tutorials</a></li>
                            <li><a href="Calls/Call_for_Grand_Challenge_Solutions.html">Call for Grand Challenge
                                Solutions</a></li>
                            <li><a href="Calls/Call_for_Poster_and_Demos.html">Call for Posters and Demos</a></li>
                            <li><a href="Calls/Call_for_Doctoral_Symposium.html">Call for Doctoral Symposium</a></li>
                        </ul>
                    </li>
                    <li class="menu-has-children"><a href="">Committee</a>
                        <ul>
                            <li><a href="Committees/Organizing_Committee.html">Organizing Committee</a></li>
                            <li><a href="Committees/Program_Committee.html">Program Committee</a></li>
                            <li><a href="Committees/Industry_PC.html">Industry PC</a></li>
                            <li><a href="Committees/Poster_Demo_PC.html">Poster and Demo PC</a></li>
                        </ul>
                    </li>
                    <li class="menu-has-children"><a href="">Conference Info</a>
                        <ul>
                            <li><a href="ConferenceInfo/Important_Dates.html">Important Dates</a></li>
                            <li><a href="ConferenceInfo/Venue_Information.html">Venue Information</a></li>
                            <li><a href="ConferenceInfo/Past_DEBS_Events.html">Past DEBS Events</a></li>
                            <li><a href="ConferenceInfo/Photo_Gallery.html">Photo Gallery</a></li>
                            <li><a href="ConferenceInfo/Accommodation.html">Accommodation</a></li>
                            <li><a href="ConferenceInfo/Visa_Information.html">Visa Information</a></li>
                        </ul>
                    </li>
                    <li class="menu-has-children"><a href="">Program</a>
                        <ul>
                            <li><a href="Program/DEBS2019_Awards.html">DEBS 2019 Awards</a></li>
                            <li><a href="Program/Full_Program.html">Full Program</a></li>
                            <li><a href="Program/Keynotes.html">Keynote Speakers</a></li>
                            <li><a href="Program/DEBS_Summer_School.html">DEBS Summer School</a></li>
                            <li><a href="Program/Tutorials.html">Tutorials</a></li>
                            <li><a href="Program/Accepted_Papers.html">Accepted Papers</a></li>
                        </ul>
                    </li>
                    <li class="menu-has-children"><a href="" class="bg-success"
                                                     style="background-color:#8ab92d !important; color: #fff !important;">Registration</a>
                        <ul>
                            <li><a href="Registration/Conference_Registration.html">Conference Registration</a></li>
                            <li><a href="Registration/Camera_Ready_Instruction.html">Camera Ready Instructions</a></li>
                            <li><a href="Registration/Scholarships.html">Scholarships</a></li>
                        </ul>
                    </li>
                </ul>
            </nav><!-- #nav-menu-container -->
        </div>
    </div>
</header><!-- #header -->


<!-- start banner Area -->
<section class="banner-area relative" id="banner">
    <div class="overlay overlay-bg"></div>
    <div class="container">
        <div class="row fullscreen d-flex align-items-center justify-content-center">
            <div class="banner-content col-lg-9 col-md-12">
                <h6>13th ACM International Conference on Distributed and Event-Based Systems</h6>
                <h1 class="text-white">
                    DEBS 2019
                </h1>
                <!--<div class="countdown">
                    <div id="timer" class="text-white"></div>
                </div>-->
                <h4><span class="lnr lnr-calendar-full"></span> 24th - 28th June, 2019</h4>
                <h4><span class="lnr lnr-map"></span> Darmstadtium, <br> Schloßgraben 1, 64283 Darmstadt</h4>
            </div>
        </div>
    </div>
</section>
<!-- End banner Area -->


<div class="whole-wrap">
    <div class="container">
        <div class="section-top-border" style="padding:50px 0px 10px;">
            <!--<h3 class="mb-30">Definition</h3>-->
            <div class="row">
                <div class="col-lg-9">
                    <div class="section-top-border" style="padding:20px 0px;">
                        <div class="single-defination">
                            <h4 class="mb-20"><b>Please, find below the open access links to all published work of the DEBS 2019 conference.</b></h4>
                            <h2 class="mb-20">SESSION: Keynotes</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338221">How Hardware
                                Evolution is
                                Driving Software Systems</a></h3>
                            <h4 class="mb-20">Gustavo Alonso</h4>
                            <p class="justifyAlignment">Computing Systems are undergoing a multitude of interesting
                                changes:
                                from the
                                platforms (cloud, appliances) to the workloads, data types, and operations (big
                                data, machine learning). Many of these changes are driven or being tackled
                                through innovation in hardware even to the point of having fully specialized
                                designs for particular applications. In this talk I will review some of the most
                                important changes happening in hardware and discuss how they affect system
                                design as well as the opportunities they create. I will focus on data processing
                                with an emphasis on streams and event based systems but also discuss
                                applications in other areas. I will also briefly discuss how these trends are
                                likely to result in a very different form of IT, and consequently of Computer
                                Science, from the one we know today.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338222">Conceptual
                                Modeling
                                of
                                Event-Based Systems</a></h3>

                            <h4 class="mb-20">Wolfgang Reisig</h4>
                            <p class="justifyAlignment">Quantitative models in informatics are well accepted and
                                employed,
                                whereas
                                qualitative, conceptual, modeling is frequently considered with scepticism: huge
                                effort is said to trade for poor benefit.</p>
                            <p class="justifyAlignment">In this talk I discuss criteria for adequate conceptual models
                                of
                                event driven
                                systems, and discuss what kind of benefit such models may yield.</p>
                            <p class="justifyAlignment">In particular, I will argue that an adequate model supports not
                                only
                                understanding, abstraction, structure, behavior, and user interaction. In
                                addition, a lot of nontrivial, deep insight can be gained, including invariants
                                in a broad sense, with e.g. models in physics as a role model.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338226">Industry Talk:
                                Serverless
                                Composition of Serverless Functions</a></h3>
                            <h4 class="mb-20">Olivier Tardieu</h4>


                            <p class="justifyAlignment">In a few short years, the Function-as-a-Service paradigm has
                                revolutionized how
                                we think about distributed event processing. Within seconds, developers can
                                deploy and run event-driven functions in the cloud that scale on demand. CIOs
                                love the high availability and zero administration. CFOs love the fine-grained,
                                pay-as-you-go pricing model.</p>
                            <p class="justifyAlignment">Most FaaS platforms today are biased toward (if not restricted
                                to)
                                simple
                                functions, functions that only run for a short while, use limited CPU and
                                memory, and process relatively small amounts of data. In this talk, we will get
                                a closer look at FaaS platforms (using Apache OpenWhisk as our exemplar) to
                                understand these trade-offs.</p>
                            <p class="justifyAlignment">Functions are not applications. To build compelling FaaS
                                applications we need to
                                compose functions. In this talk, we will compare approaches to function
                                composition both from a developer and from a system's perspective. We will show
                                how composition can dramatically expand the scope of FaaS.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338223">Open Problems in
                                Stream
                                Processing: A Call To Action</a></h3>

                            <h4 class="mb-20">Tyler Akidau</h4>


                            <p class="justifyAlignment">In the last four years, stream processing has gone from niche to
                                mainstream, with
                                real-time data processing systems gaining traction in not only fast-moving
                                startups, but also their more skeptical and cautious enterprise brethren. In
                                light of such pervasive adoption, is it safe to say we've we finally reached the
                                point where stream processing is a solved commodity? Are we done and ready to
                                move on to the next big thing?</p>
                            <p class="justifyAlignment">In this talk, I will argue that the answer to those questions is
                                conclusively
                                "no": stream processing as a field of research is alive and well. In fact, as
                                streaming systems evolve to look more and more alike, the need for active
                                exploration of new ideas is all the more pressing. And though streaming systems
                                are more capable and robust than ever, they remain in many ways difficult to
                                use, difficult to maintain, and difficult to understand. But we can change
                                that.</p>
                            <p class="justifyAlignment">I don't claim to have all the answers; no one does. But I do
                                have a
                                few ideas of
                                where we can start. And by sharing my thoughts on some of the more interesting
                                open problems in stream processing, and encouraging others to share theirs, I'm
                                hoping that we as a research community can work together to help move the needle
                                just a little bit further.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338224">Unifying
                                Messaging,
                                Queuing,
                                Streaming and Light Weight Compute for Online Event Processing</a></h3>

                            <h4 class="mb-20">Karthik Ramasamy</h4>


                            <p class="justifyAlignment">Online event processing are abound ranging from web and mobile
                                applications to
                                data processing. Such event processing applications often require the ability to
                                ingest, store, dispatch and process events. Until now, supporting all of these
                                needs has required different systems for each task -- stream processing engines,
                                messaging queuing middleware, and pub/sub messaging systems. This has led to the
                                unnecessary complexity for the development of such applications and operations
                                leading to increased barrier to adoption in the enterprises.</p>
                            <p class="justifyAlignment">In this keynote, Karthik will outline the need to unify these
                                capabilities in a
                                single system and make it easy to develop and operate at scale. Karthik will
                                delve into how Apache Pulsar was designed to address this need with an elegant
                                architecture. Apache Pulsar is a next generation distributed pub-sub system that
                                was originally developed and deployed at Yahoo and running in production in more
                                than 100+ companies. Karthik will explain how the architecture and design of
                                Pulsar provides the flexibility to support developers and applications needing
                                any combination of queuing, messaging, streaming and lightweight compute for
                                events. Furthermore, he will provide real life use cases how Apache Pulsar is
                                used for event processing ranging from data processing tasks to web processing
                                applications.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338225">The Global AI
                                Supercomputer</a>
                            </h3>

                            <h4 class="mb-20">Donald Kossmann</h4>


                            <p class="justifyAlignment">The number of computers in the world is still growing at an
                                exponential rate. For
                                instance, there are 9 Billion new micro-controllers shipped every year and that
                                is on top of other devices such as mobile phones and servers in the cloud and
                                on-premise. This talk takes a different perspective on this trend and argues
                                that it makes sense to look at all these micro-controllers, devices, and servers
                                as one big supercomputer.</p>
                            <p class="justifyAlignment">The talk gives examples that illustrate how to make this
                                supercomputer
                                sustainable, secure, programable, and useful.</p>

                        </div>
                    </div>

                    <div class="section-top-border" style="padding:20px 0px;">
                        <div class="single-defination">
                            <h2 class="mb-20">SESSION: Research Track</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329509">STRETCH: Scalable
                                and
                                Elastic
                                Deterministic Streaming Analysis with Virtual Shared-Nothing Parallelism</a></h3>

                            <h4 class="mb-20">Hannaneh Najdataei, Yiannis Nikolakopoulos, Marina Papatriantafilou,
                                Philippas Tsigas,
                                Vincenzo Gulisano</h4>

                            <p class="justifyAlignment">Despite the established scientific knowledge on efficient
                                parallel and elastic
                                data stream processing, it is challenging to combine generality and high level
                                of abstraction (targeting ease of use) with fine-grained processing aspects
                                (targeting efficiency) in stream processing frameworks. Towards this goal, we
                                propose STRETCH, a framework that aims at guaranteeing (i) high efficiency in
                                throughput and latency of stateful analysis and (ii) fast elastic
                                reconfigurations (without requiring state transfer) for intra-node streaming
                                applications. To achieve these, we introduce virtual shared-nothing
                                parallelization and propose a scheme to implement it in STRETCH, enabling users
                                to leverage parallelization techniques while also taking advantage of
                                shared-memory synchronization, which has been proven to boost the scaling-up of
                                streaming applications while supporting determinism. We provide a
                                fully-implemented prototype and, together with a thorough evaluation,
                                correctness proofs for its underlying claims supporting determinism and a model
                                (also validated empirically) of virtual shared-nothing and pure shared-nothing
                                scalability behavior. As we show, STRETCH can match the throughput and latency
                                figures of the front of state-of-the-art solutions, while also achieving fast
                                elastic reconfigurations (taking only a few milliseconds).</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329505">Haren: A
                                Framework
                                for Ad-Hoc
                                Thread Scheduling Policies for Data Streaming Applications</a></h3>

                            <h4 class="mb-20">Dimitris Palyvos-Giannas,
                                Vincenzo Gulisano,
                                Marina Papatriantafilou</h4>


                            <p class="justifyAlignment">In modern Stream Processing Engines (SPEs), numerous diverse
                                applications, which
                                can differ in aspects such as cost, criticality or latency sensitivity, can
                                co-exist in the same computing node. When these differences need to be
                                considered to control the performance of each application, custom scheduling of
                                operators to threads is of key importance (e.g., when a smart vehicle needs to
                                ensure that safety-critical applications always have access to computational
                                power, while other applications are given lower, variable priorities).</p>
                            <p class="justifyAlignment">Many solutions have been proposed regarding schedulers that
                                allocate threads to
                                operators to optimize specific metrics (e.g., latency) but there is still lack
                                of a tool that allows arbitrarily complex scheduling strategies to be seamlessly
                                plugged on top of an SPE. We propose Haren to fill this gap. More specifically,
                                we (1) formalize the thread scheduling problem in stream processing in a general
                                way, allowing to define ad-hoc scheduling policies, (2) identify the bottlenecks
                                and the opportunities of scheduling in stream processing, (3) distill a compact
                                interface to connect Haren with SPEs, enabling rapid testing of various
                                scheduling policies, (4) illustrate the usability of the framework by
                                integrating it into an actual SPE and (5) provide a thorough evaluation. As we
                                show, Haren makes it is possible to adapt the use of computational resources
                                over time to meet the goals of a variety of scheduling policies.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329506">Reinforcement
                                Learning Based
                                Policies for Elastic Stream Processing on Heterogeneous Resources</a></h3>

                            <h4 class="mb-20">Gabriele Russo Russo,
                                Valeria Cardellini,
                                Francesco Lo Presti</h4>

                            <p class="justifyAlignment">Data Stream Processing (DSP) has emerged as a key enabler to
                                develop pervasive
                                services that require to process data in a near real-time fashion. DSP
                                applications keep up with the high volume of produced data by scaling their
                                execution on multiple computing nodes, so as to process the incoming data flow
                                in parallel. Workloads variability requires to elastically adapt the application
                                parallelism at run-time in order to avoid over-provisioning. Elasticity policies
                                for DSP have been widely investigated, but mostly under the simplifying
                                assumption of homogeneous infrastructures. The resulting solutions do not
                                capture the richness and inherent complexity of modern infrastructures, where
                                heterogeneous computing resources are available on-demand. In this paper, we
                                formulate the problem of controlling elasticity on heterogeneous resources as a
                                Markov Decision Process (MDP). The resulting MDP is not easily solved by
                                traditional techniques due to state space explosion, and thus we show how linear
                                Function Approximation and Tile Coding can be used to efficiently compute
                                elasticity policies at run-time. In order to deal with parameters uncertainty,
                                we integrate the proposed approach with Reinforcement Learning algorithms. Our
                                numerical evaluation shows the efficacy of the presented solutions compared to
                                standard methods in terms of accuracy and convergence speed.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329508">Multistage
                                Adaptive
                                Load
                                Balancing for Big Active Data Publish Subscribe Systems</a></h3>
                            
                                <h4 class="mb-20">Hang Nguyen,
                                Md Yusuf Sarwar Uddin,
                                Nalini Venkatasubramanian</h4>
                            

                            <p class="justifyAlignment">In this paper, we address issues in the design and operation
                                of a Big Active Data
                                Publish Subscribe (BAD Pub/Sub) systems to enable the next generation of
                                enriched notification systems that can scale to societal levels. The proposed
                                BAD Pub/Sub system will aim to ingest massive amounts of data from heterogeneous
                                publishers and sources and deliver customized, enriched notifications to end
                                users (subscribers) that express interests in these data items via parameterized
                                channels. To support scalability, we employ a hierarchical architecture that
                                combines a back-end big data cluster (to receive publications and data feeds,
                                store data and process subscriptions) with a client-facing distributed broker
                                network that manages user subscriptions and scales the delivery process. A key
                                aspect of our broker capacity is its ability to aggregate subscriptions from end
                                users to immensely reduce the end to end overheads and loads. The skewed
                                distribution of subscribers, their interests and the dynamic nature of societal
                                scale publications, create load imbalance in the distributed broker network. We
                                mathematically formulate the notion of broker load in this setting and derive an
                                optimization problem to minimize the maximum load (an NP-hard problem). We
                                propose a staged approach for broker load balancing that executes in multiple
                                stages --- initial placement of brokers to subscribers, dynamic subscriber
                                migration during operation to handle transient and instantaneous loads and
                                occasional shuffles to re-stabilize the system. We develop a prototype
                                implementation of our staged load balancing on a real BAD Pub/Sub testbed
                                (multinode cluster) with a distributed broker network and conduct experiments
                                using real world workloads. We further evaluate our schemes via a detailed
                                simulation studies.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3338535">Cooperative
                                Offloading in
                                Context-Aware Networks: A Game-Theoretic Approach</a></h3>
                            
                                <h4 class="mb-20">Tobias Meuser,
                                Daniel Bischoff,
                                Björn Richerzhagen,
                                Ralf Steinmetz</h4>
                            

                            <p class="justifyAlignment">Vehicles exchange Floating Car Data (FCD) to improve
                                awareness beyond their local
                                perception and thereby increase traffic safety and comfort. If the FCD is
                                required at distant locations, FCD can be shared using the cellular network to
                                notify vehicles early of upcoming road events. However, this monitoring of the
                                roads congests the cellular network, which is already utilized by other
                                applications. The available bandwidth for monitoring is expected to decrease
                                further with the introduction of fully autonomous vehicles.</p>
                            <p class="justifyAlignment">In this paper, we propose a hybrid dissemination approach
                                for the distribution of
                                road events in vehicular networks. Our approach aims to utilize only a
                                predefined bandwidth for information exchange, which is achieved by two
                                mechanisms: (i) the offloading of information to Wifi-based Vehicle to Vehicle
                                (V2V) communication and (ii) the filtering of low-impact information. We offload
                                the information to Wifi-based communication using non-cooperative game-theory:
                                Each vehicle chooses the minimum impact of information it wants to receive via
                                the cellular network. Through cooperation, the vehicles in proximity might
                                provide information the other vehicles cannot receive. In the evaluation, we
                                show that our approach significantly improves the data quality at the vehicles
                                compared to traditional offloading approaches while sticking to the predefined
                                bandwidth constraints.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329512">Location-Centric
                                View
                                Selection
                                in a Location-Based Feed-Following System</a></h3>
                            <h4 class="mb-20">Kaiji Chen,
                            Yongluan Zhou</h4>

                            <p class="justifyAlignment">Location-based feed-following is a trending service that can
                                provide
                                contextually
                                relevant information to users based on their locations. In this paper, we
                                consider the view selection problem in a location-based feed-following system
                                that continuously provides aggregated query results over feeds that are located
                                within a certain range from users. Previous solutions adopt a user-centric
                                approach and require re-optimizations of the view selection once users move
                                their locations. Such methods limit the system's scalability to the number of
                                users and can be very costly when a substantial number of users move their
                                locations. To solve the problem, we propose the new concept of location-centric
                                query plans. In this approach, we use a grid to partition the space into cells
                                and generate view selection and query processing plans for each cell, and user
                                queries will be evaluated using the query plans associated with the users'
                                current locations. In this way, the problem's complexity and dynamicity is
                                largely determined by the granularity of the grid instead of the number of
                                users. To minimize the query processing cost, we further propose an algorithm to
                                generate an optimized set of materialized views to store the aggregated events
                                of some feeds and a number of location-centric query plans for each grid cell.
                                The algorithm can also efficiently adapt the plans according to the movement of
                                the users. We implement a prototype system by using Redis as the back-end
                                in-memory storage system for the materialized views and conduct extensive
                                experiments over two real datasets to verify the effectiveness and efficiency of
                                our approach.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329504">Incremental Event
                                Calculus for
                                Run-Time Reasoning</a></h3>

                            <h4 class="mb-20">Efthimis Tsilionis,
                                Alexander Artikis,
                                Georgios Paliouras</h4>
                            

                            <p class="justifyAlignment">We present a system for online, incremental composite event
                                recognition. In
                                streaming environments, the usual case is for data to arrive with a (variable)
                                delay from, and to be retracted/revised by the underlying sources. We propose
                                RTECinc, an incremental version of RTEC, a composite event recognition engine
                                with a formal, declarative semantics, that has been shown to scale to several
                                real-world data streams. RTEC deals with delayed arrival and retraction of
                                events by computing at each query time composite event intervals from scratch.
                                This often results to redundant computations. Instead, RTECinc deals with delays
                                and retractions in a more efficient way, by updating only the affected events.
                                We evaluate RTECinc theoretically, presenting a complexity analysis, and show
                                the conditions in which it outperforms RTEC. Moreover, we compare RTECinc and
                                RTEC experimentally using two real-world datasets. The results are compatible
                                with our theoretical analysis and show that RTECinc may outperform RTEC.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329501">LEAD: A Formal
                                Specification
                                For Event Processing</a></h3>
                            
                                <h4 class="mb-20">Anas Al Bassit,
                                Sabri Skhiri,
                                Hejer Ammar</h4>
                            

                            <p class="justifyAlignment">Processing event streams is an increasingly important area for
                                modern businesses
                                aiming to detect and efficiently react to critical situations in near real-time.
                                The need to govern the behavior of systems where such streams exist has led to
                                the development of numerous Complex Event Processing (CEP) engines, capable of
                                detecting patterns and analyzing event streams. Although current CEP systems
                                provide real-time analysis foundations for a variety of applications, several
                                challenges arise due to languages' limitations and imprecise semantics, as well
                                as the lack of power to handle big data requirements. In this paper, we discuss
                                such systems, analyzing some of the most sensitive issues in this domain.
                                Further in this context, we present our contributions expressed in LEAD, a
                                formal specification for processing complex events. LEAD provides an algebra
                                that consists of a set of operators for constructing complex events (patterns),
                                temporally restricting the construction process and choosing among several
                                selection and consumption policies. We show how to build LEAD rules to
                                demonstrate the expressive power of our approach. Furthermore, we introduce a
                                novel approach of interpreting these rules into a logical execution plan, built
                                with temporal prioritized colored petri nets.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329502">C-Sprite:
                                Efficient
                                Hierarchical Reasoning for Rapid RDF Stream Processing</a></h3>
                            
                                <h4 class="mb-20">Pieter Bonte,
                                Riccardo Tommasini,
                                Filip De Turck,
                                Femke Ongenae,
                                Emanuele Della Valle</h4>
                            

                            <p class="justifyAlignment">Many domains, such as the Internet of Things and Social Media,
                                demand to combine
                                data streams with background knowledge to enable meaningful analysis in
                                real-time. When background knowledge takes the form of taxonomies and class
                                hierarchies, Semantic Web technologies are valuable tools and their extension to
                                data streams, namely RDF Stream processing (RSP), offers the opportunity to
                                integrate the background knowledge with RDF streams. In particular, RSP Engines
                                can continuously answer SPARQL queries while performing reasoning. However,
                                current RSP engines are at risk of failing to perform reasoning at the required
                                throughput. In this paper, we formalize continuous hierarchical reasoning. We
                                propose an optimized algorithm, namely C-Sprite, that operates in constant time
                                and scales linearly in the number of continuous queries (to be evaluated in
                                parallel). We present two implementations of C-Sprite: one exploits a language
                                feature often found in existing Stream Processing engines while the other is an
                                optimized implementation. The empirical evaluation shows that the proposed
                                solution is at least twice as fast as current approaches.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329510">ASSED: A
                                Framework for
                                Identifying Physical Events through Adaptive Social Sensor Data Filtering</a></h3>
                            
                                <h4 class="mb-20">Abhijit Suprem,
                                Calton Pu</h4>
                            

                            <p class="justifyAlignment">Physical event detection has long been the domain of static
                                event
                                processors
                                operating on numeric sensor data. This works well for large scale strong-signal
                                events such as hurricanes, and important classes of events such as earthquakes.
                                However, for a variety of domains there is insufficient sensor coverage, e.g.,
                                landslides, wildfires, and flooding. Social networks have provided massive
                                volume of data from billions of users, but data from these generic social
                                sensors contain much more noise than physical sensors. One of the most difficult
                                challenges presented by social sensors is concept drift, where the terms
                                associated with a phenomenon evolve and change over time, rendering static
                                machine learning (ML) classifiers less effective. To address this problem, we
                                develop the ASSED (Adaptive Social Sensor Event Detection) framework with an
                                ML-based event processing engine and show how it can perform simple and complex
                                physical event detection on strong- and weak-signal with low-latency, high
                                scalability, and accurate coverage. Specifically, ASSED is a framework to
                                support continuous filter generation and updates with machine learning using
                                streaming data from high-confidence sources (physical and annotated sensors) and
                                social networks. We build ASSED to support procedures for integrating
                                high-confidence sources into social sensor event detection to generate
                                high-quality filters and to perform dynamic filter selection by tracking its own
                                performance. We demonstrate ASSED capabilities through a landslide detection
                                application that detects almost 350% more landslides compared to static
                                approaches. More importantly, ASSED automates the handling of concept drift:
                                four years after initial data collection and classifier training, ASSED achieves
                                event detection accuracy of 0.988 (without expert manual intervention), compared
                                to 0.762 for static approaches.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329507">Khronos:
                                Middleware for
                                Simplified Time Management in CPS</a></h3>
                            
                                <h4 class="mb-20">Stefanos Peros,
                                Stéphane Delbruel,
                                Sam Michiels,
                                Wouter Joosen,
                                Danny Hughes</h4>
                            

                            <p class="justifyAlignment">Cyber Physical Systems (CPS) combine communication, computation
                                and
                                data storage
                                capabilities to oversee and control physical processes in domains including
                                manufacturing, medical monitoring and smart grids. CPS behavior can be remotely
                                monitored by aggregating event data from various sensors, forwarded over
                                wireless networks. One of the main challenges for CPS application developers is
                                to manage event arrival-time boundaries and to trade off between timeliness and
                                completeness: waiting too long until all events arrive can fail to produce a
                                useful result, while not waiting long enough may lead to faults because the
                                status information is incomplete. Monitoring the production lines in a factory,
                                for example, depends on the aggregation of event data from multiple sensors in
                                the distributed CPS, such as temperature and movement. Yet, predicting
                                time-boundaries for individual event arrivals is difficult, if not impossible,
                                for an application developer, because the wireless network and the sensing
                                devices introduce latencies which vary continuously along with the load, status
                                or environmental conditions of the network and the sensors. This paper proposes
                                Khronos, a middleware that automatically determines timeouts for event arrivals
                                that improve timeliness, given completeness constraint(s) specified by the CPS
                                application developer and taking into account variations in event propagation
                                delays. Extensive evaluations on a physical testbed show that Khronos
                                considerably improves timeliness under varying network configurations and
                                conditions, while satisfying application-specific completeness constraints.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329511">Data Repair for
                                Distributed,
                                Event-based IoT Applications</a></h3>
                            
                                <h4 class="mb-20">Wei-Tsung Lin,
                                Fatih Bakir,
                                Chandra Krintz,
                                Rich Wolski,
                                Markus Mock</h4>
                            

                            <p class="justifyAlignment">Motivated by the growth of Internet of Things (IoT) technologies
                                and
                                the volumes
                                and velocity of data that they can and will produce, we investigate automated
                                data repair for event-driven, IoT applications. IoT devices are heterogeneous in
                                their hardware architectures, software, size, cost, capacity, network
                                capabilities, power requirements, etc. They must execute in a wide range of
                                operating environments where failures and degradations of service due to
                                hardware malfunction, software bugs, network partitions, etc. cannot be
                                immediately remediated. Further, many of these failure modes cause corruption in
                                the data that these devices produce and in the computations "downstream" that
                                depend on this data.</p>
                            <p class="justifyAlignment">To "repair" corrupted data from its origin through its
                                computational
                                dependencies
                                in a distributed IoT setting, we explore SANS-SOUCI--a system for automatically
                                tracking causal data dependencies and re-initiating dependent computations in
                                event-driven IoT deployment frameworks. SANS-SOUCI presupposes an event-driven
                                programming model based on cloud functions, which we extend for portable
                                execution across IoT tiers (device, edge, cloud). We add fast, persistent,
                                append-only storage and versioning for efficient data robustness and durability.
                                SANS-SOUCI records events and their causal dependencies using a distributed
                                event log and repairs applications dynamically, across tiers via replay. We
                                evaluate SANS-SOUCI using a portable, open source, distributed IoT platform,
                                example applications, and microbenchmarks. We find that SANS-SOUCI is able to
                                perform repair for both software (function) and sensor produced data corruption
                                with very low overhead.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329500">Static
                                Termination Analysis
                                for
                                Event-driven Distributed Algorithms</a></h3>
                            
                                <h4 class="mb-20">Felix Wiemuth,
                                Peter Amthor,
                                Winfried E. Kühnhauser</h4>
                            
                            <p class="justifyAlignment">Termination is an important non-functional property of
                                distributed
                                algorithms. In
                                an event-driven setting, the interesting aspect of termination is the
                                possibility of control flow loops through communication, which this paper aims
                                to investigate.</p>
                            <p class="justifyAlignment">In practice, it is often difficult to spot the possible
                                communication behaviour
                                of an algorithm at a glance. With a static analysis, the design process can be
                                supported by visualizing possible flow of messages and give hints on possible
                                sources of non-termination.</p>
                            <p class="justifyAlignment">We propose a termination analysis for distributed algorithms
                                formulated in an
                                event-driven specification language. The idea is to construct a message flow
                                graph describing the possible communication between components (input-action
                                pairs). We show that acyclicity of that graph implies termination. While many
                                interesting algorithms indeed contain cycles, we also suggest ways of detecting
                                cycles which cannot lead to non-termination.</p>
                            <p class="justifyAlignment">As a practical evaluation, we describe a concrete programming
                                language together
                                with a tool for automated termination analysis.</p>
                        </div>
                    </div>

                    <div class="section-top-border" style="padding:20px 0px;">
                        <div class="single-defination">
                            <h2 class="mb-20">SESSION: Industry Track</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329762">Composite Event
                                Recognition
                                for
                                Maritime Monitoring</a></h3>
                            
                                <h4 class="mb-20">Manolis Pitsikalis,
                                Alexander Artikis,
                                Richard Dreo,
                                Cyril Ray,
                                Elena Camossi,
                                Anne-Laure Jousselme</h4>
                            

                            <p class="justifyAlignment">Maritime monitoring systems support safe shipping as they allow
                                for
                                the real-time
                                detection of dangerous, suspicious and illegal vessel activities. We present
                                such a system using the Run-Time Event Calculus, a composite event recognition
                                system with formal, declarative semantics. For effective recognition, we
                                developed a library of maritime patterns in close collaboration with domain
                                experts. We present a thorough evaluation of the system and the patterns both in
                                terms of predictive accuracy and computational efficiency, using real-world
                                datasets of vessel position streams and contextual geographical information.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329763">Uncertainty-Aware
                                Event
                                Analytics over Distributed Settings</a></h3>
                            
                                <h4 class="mb-20">Nikos Giatrakos,
                                Alexander Artikis,
                                Antonios Deligiannakis,
                                Minos Garofalakis</h4>
                            

                            <p class="justifyAlignment">In complex event processing (CEP), simple derived event tuples
                                are
                                combined in
                                pattern matching procedures to derive complex events (CEs) of interest. Big Data
                                applications analyze event streams online and extract CEs to support decision
                                making procedures. At massive scale, such applications operate over distributed
                                networks of sites where efficient CEP requires reducing communication as much as
                                possible. Besides, events often encompass various types of uncertainty.
                                Therefore, massively distributed Big event Data applications in a world of
                                uncertain events call for communication-efficient, uncertainty-aware CEP
                                solutions, which is the focus of this work. As a proof-of-concept for the
                                applicability of our techniques, we show how we bridge the gap between two
                                recent CEP prototypes which use the same CEP engine and each extend it towards
                                only one of the dimensions of distribution and uncertainty.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3329761">Continuous
                                Distributed
                                Monitoring in the Evolved Packet Core</a></h3>
                            
                                <h4 class="mb-20">Romaric Duvignau,
                                Marina Papatriantafilou,
                                Konstantinos Peratinos,
                                Eric Nordström,
                                Patrik Nyman</h4>
                            

                            <p class="justifyAlignment">For performance analysis, optimization and anomaly detection,
                                there
                                is strong
                                need to monitor industrial systems, which, along modern datacenter
                                infrastructures, feature a high level of decentralization. Continuous
                                Distributed Monitoring (CDM) corresponds to the task of continuously keeping
                                track of statistics from different distributed nodes. We review the feasibility
                                of implementing state-of-the-art CDM algorithms in a large-scale, distributed,
                                performance-critical production system. The study is on the Evolved Packet Core
                                (EPC), an inherently distributed component of the 4G architecture, for
                                processing mobile broadband data. In this work, we propose adjustments to
                                classical models that are needed to account for communication and computation
                                delays and the hierarchical architecture present in production systems. We
                                further demonstrate efficient CDM implementations in the EPC, and analyze
                                trade-offs of accuracy versus savings in communication, as well as availability
                                of the monitoring system.</p>


                            <h2 class="mb-20">TUTORIAL SESSION: Tutorials</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332464">A Modern Approach
                                to
                                Situation
                                Awareness: The Ultimate Challenge for Event Processing</a></h3>
                            
                                <h4 class="mb-20">Christoph Brandt,
                                Dieter Gawlick</h4>
                            

                            <p class="justifyAlignment">Wikipedia states: "Situational awareness or situation awareness
                                (SA)
                                is the
                                perception of environmental elements and events with respect to time or space,
                                the comprehension of their meaning, and the projection of their future status."
                                [1]</p>
                            <p class="justifyAlignment">In 1976 John Boyd published a model he named OODA-loop (Observe,
                                Orient, Decide,
                                and Act) to capture the main elements of Situation Awareness. However, this is a
                                pre-IT model that needs to be updated to leverage as much IT technology as
                                possible; KIDS (Knowledge Intensive Data-management Systems) is such a model
                                [6]. KIDS captures data, identifies abnormal conditions, transforms the data
                                related to these abnormal conditions into the language of domain experts, give
                                guidance to the interpretation (classification and assessment), and recommends
                                reactions. While many required technologies, especially event processing, are
                                available they have to be embedded/organized into a comprehensive SA model; some
                                of these technologies must be extended and (significantly) improved.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332463">Correctness and
                                Consistency
                                of
                                Event-Based Systems</a></h3>
                            
                                <h4 class="mb-20">Opher Etzion</h4>
                            

                            <p class="justifyAlignment">Event-based systems encounter challenges of correctness and
                                consistency.
                                Correctness means that the execution results match the intention of the
                                designer. Consistency means that different data elements that co-exist within a
                                certain system creates an internal consistency with respect to the system's
                                requirements. In this tutorial, we cover the different aspects of correctness
                                and consistency. We discuss issues of correctness with respect of the temporal
                                properties of the system, such as order of events, and boundaries of time
                                windows. We further discuss the different aspects of fine-tuning required in
                                event-based system, where different semantic interpretations are possible, such
                                as: repeating events, or consumption. The consistency discussion relates to two
                                classic issues in the data management world: data dependencies and integrity
                                constraint enforcement. Since event-based systems typically consist of loosely
                                coupled component architecture in distributed environment, the challenge is
                                compliance with data dependencies and assertions about consistency. Finally, yet
                                importantly, we discuss the validation of event-based systems by using static
                                and dynamic analysis.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332462">An Outlook to
                                Declarative
                                Languages for Big Steaming Data</a></h3>
                            
                                <h4 class="mb-20">Riccardo Tommasini,
                                Sherif Sakr,
                                Marco Balduini,
                                Emanuele Della Valle</h4>
                            

                            <p class="justifyAlignment">In the Big Data context, data streaming systems have been
                                introduced
                                to tame
                                velocity and enable reactive decision making. However, approaching such systems
                                is still too complex due to the paradigm shift they require, i.e., moving from
                                scalable batch processing to continuous analysis and detection. Initially,
                                modern big stream processing systems (e.g., Flink, Spark, Storm) have been
                                lacking the support of declarative languages to express the streaming-based data
                                processing tasks and have been mainly relying on providing low-level APIs for
                                the end-users to implement their tasks. However, recently, this fact has been
                                changing and most of them started to provide SQL-like languages for their
                                end-users.</p>
                            <p class="justifyAlignment">In general, declarative Languages are playing a crucial role in
                                fostering the
                                adoption of Stream Processing. This tutorial focuses on introducing various
                                approaches for declarative querying of the state-of-the-art big data streaming
                                frameworks. In addition, we provide guidelines and practical examples on
                                developing and deploying Stream Processing applications using a variety of
                                SQL-like languages, such as Flink-SQL, KSQL and Spark Streaming SQL.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332465">Developing
                                Distributed
                                Systems
                                with Multitier Programming</a></h3>
                            
                                <h4 class="mb-20">Pascal Weisenburger,
                                Guido Salvaneschi</h4>
                            

                            <p class="justifyAlignment">Developing distributed systems is a complex task that requires
                                to
                                program
                                different peers, often using several languages on different platforms, writing
                                communication code and handling data serialization and conversion.</p>
                            <p class="justifyAlignment">We show how the multitier programming paradigm can alleviate
                                these
                                issues,
                                supporting a development model where all peers in the system can be written in
                                the same language and coexist in the same compilation units, communication code
                                is automatically inserted by the compiler and the language abstracts over data
                                conversion and serialization. We present multitier programming abstractions,
                                discuss their applicability step by step for the development of small
                                applications and discuss larger case studies on distributed stream processing,
                                like Apache Flink and Apache Gearpump.</p>
                        </div>
                    </div>

                    <div class="section-top-border" style="padding:20px 0px;">
                        <div class="single-defination">

                            <h2 class="mb-20">SESSION: DEBS Grand Challenge</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3334135">The DEBS 2019
                                Grand
                                Challenge</a></h3>
                            
                                <h4 class="mb-20">Oleh Bodunov,
                                Vincenzo Gulisano,
                                Hannaneh Najdataei,
                                Zbigniew Jerzak,
                                André Martin,
                                Pavel Smirnov,
                                Martin Strohbach,
                                Holger Ziekow</h4>
                            

                            <p class="justifyAlignment">The ACM DEBS 2019 Grand Challenge is the ninth in a series of
                                challenges which
                                seek to provide a common ground and evaluation criteria for a competition aimed
                                at both research and industrial event-based systems. The focus of the 2019 Grand
                                Challenge is on the application of machine learning to LiDAR data. The goal of
                                the challenge is to perform classification of objects found in urban
                                environments and sensed in several 3D scenes by the LiDAR. The applications of
                                LIDAR and object detection go well beyond autonomous vehicles and are suitable
                                for use in agriculture, waterway maintenance and flood prevention, and
                                construction. This paper describes the specifics of the data streams provided in
                                the challenge as well as the benchmarking platform that supports the testing of
                                corresponding solutions.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3330298">3-D Urban Objects
                                Detection
                                and
                                Classification From Point Clouds</a></h3>
                            
                                <h4 class="mb-20">Yassin Alkhalili,
                                Manisha Luthra,
                                Amr Rizk,
                                Boris Koldehofe</h4>
                            

                            <p class="justifyAlignment">In this paper, we present our approach to solve the DEBS Grand
                                challenge 2019
                                which consists of classifying urban objects in different scenes that originate
                                from a LiDAR sensor. In general, at any point in time, LiDAR data can be
                                considered as a point cloud where a reliable feature extractor and a
                                classification model are required to be able to recognize 3-D objects in such
                                scenes. Herein, we propose and describe an implementation of a 3-D point cloud
                                object detection and classification system based on a 3-D global feature called
                                Ensemble of Shape Functions (ESF) and a random forest object classifier.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3330297">Real-Time Object
                                Recognition
                                from Streaming LiDAR Point Cloud Data</a></h3>
                            
                                <h4 class="mb-20">Sambasiva Rao Gangineni,
                                Harshad Reddy Nalla,
                                Saeed Fathollahzadeh,
                                Kia Teymourian</h4>
                            

                            <p class="justifyAlignment">In many robotic applications, LiDAR (Light Detection and
                                Ranging)
                                scanner is used
                                to gather data about the environment. Applications like autonomous vehicles
                                require real-time processing of LiDAR point cloud data with high accuracy.</p>
                            <p class="justifyAlignment">We describe in this paper, our implementation for DEBS 2019
                                Grand
                                Challenge for
                                an object recognition system from high-speed LiDAR data stream. Our system
                                includes a data processing pipeline with 3 main stages, 1. LiDAR data filtering
                                2. Object segmentation and noise reduction 3. Multi-class object classification
                                using Convolutional Neural Network (CNN). Our evaluation shows that we can
                                classify objects with high accuracy using the point cloud data and neural
                                network. However, we observed that the classification may fail if the object
                                segmentation is not separating objects correctly in different segments
                                especially when the objects are largely covering each other. We proposed a
                                pre-processing approach for object segmentation based on separating LiDAR data
                                into multiple area sectors before segmenting the objects.</p>
                        </div>
                    </div>

                    <div class="section-top-border" style="padding:20px 0px;">
                        <div class="single-defination">

                            <h2 class="mb-20">DEMONSTRATION SESSION: Demonstrations and Posters</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332517">axxessity: City
                                and
                                User-Centric Approach to Build Smart City Bonn</a></h3>
                            
                                <h4 class="mb-20">Pratyush Agnihotri,
                                Florian Weber,
                                Sascha Peters</h4>
                            

                            <p class="justifyAlignment">The main mission of smart cities is to offer core infrastructure
                                and quality of life to its citizens. This quality of life can be achieved by providing a
                                cleaner and sustainable environment. However, the main mission of smart cities
                                is undermined due to the existing data-centric applications. Data-centric
                                approaches feed on the data of users and lack of users privacy and security. In
                                result, smart city solutions elected by city administration are not entirely
                                adopted by citizens. We need to understand the fact that each and every city and
                                its citizen are different from each other and the same solution cannot be
                                applied to all of them. If we will accept this fact then we can offer a
                                sustainable solution which will be used by city administration but also welcomed
                                by its citizens.</p>
                            <p class="justifyAlignment">In this paper we are discussing the city and user-centric
                                solution
                                "axxessity"
                                which is designed and proposed to the city administration of Bonn. The solution
                                is powered by the Open Urban Platform. In our approach citizens and cities are
                                in the center of attention while deciding for a digitization-solution for
                                respective cities. Our achievements lie in the fact that our solution cares
                                about citizens privacy first. Moreover, the platform can be scaled and adapted
                                to the heterogeneous demands of cities and citizens. As a result, it is most
                                welcomed by citizens and accepted by the city administration. However, we accept
                                the fact that solutions and processes need to be upgraded and strengthened with
                                time. Therefore, we would like to take the opportunity to present our axxessity
                                solution and platform to show the capability of our solution followed by getting
                                valuable feedback from researchers and industry experts.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332507">Pretty Fly for a
                                VAT GUI:
                                Visualizing Event Patterns for Flight Data</a></h3>
                            
                                <h4 class="mb-20">Christian Beilschmidt,
                                Johannes Drönner,
                                Nikolaus Glombiewski,
                                Christian Heigele,
                                Jana Holznigenkemper,
                                Anna Isenberg,
                                Michael Körber,
                                Michael Mattig,
                                Andreas Morgen,
                                Bernhard Seeger</h4>
                            

                            <p class="justifyAlignment">Complex Event Processing (CEP) is the state-of-the-art
                                technology
                                for
                                continuously monitoring and analyzing streams of events. One of the key features
                                of CEP is to support pattern matching queries to detect user-defined sequences
                                of predicates on event streams. However, due to the vast amount of parameters,
                                tweaking the queries to deliver the desired results is challenging. For this
                                demonstration, we connected a database-backed CEP system (Jepc, ChronicleDB)
                                with a scientific toolbox for interactive data exploration and geo visualization
                                (Vat System), and thus allow users to interactively explore event data via CEP
                                queries. Furthermore, the pairing of these systems allows to combine the results
                                of event queries with additional non-relational data-sets such as raster data,
                                leading to insights beyond pure event-based analytics. In this demonstration, we
                                showcase the first promising results of this combination by evaluating three use
                                cases involving high-volume event data collected from aircrafts in-flight.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332512">Ping - A
                                customizable,
                                open-source information filtering system for textual data</a></h3>
                            
                                <h4 class="mb-20">Thanasis Chantzios,
                                Lefteris Zervakis,
                                Spiros Skiadopoulos,
                                Christos Tryfonopoulos</h4>
                            

                            <p class="justifyAlignment">Information filtering has emerged as a prominent paradigm of
                                timely
                                information
                                delivery; in such a setup, users submit profiles that express their information
                                needs to a server which is responsible for notifying them when information that
                                matches their profiles becomes available. Traditionally, information filtering
                                research has focused mainly on providing algorithmic solutions that enhance the
                                efficiency and effectiveness of the filtering process, and has largely neglected
                                the development of tools/systems that showcase the usefulness of the paradigm.
                                In this work, we put forward Ping, a fully-functional content-based information
                                filtering system aiming (i) to showcase the realisability of information
                                filtering and (ii) to explore and test the suitability of the existing
                                technological arsenal for information filtering tasks. The proposed system is
                                entirely based upon open-source tools and components, is customisable enough to
                                be adapted for different textual information filtering tasks, and puts emphasis
                                in user profile expressivity, intuitive UIs, and timely information delivery. To
                                assess the customisability of Ping, we deployed it in two distinct application
                                scenarios, and assessed its performance under both scenarios.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332510">Maritime Event
                                Recognition</a>
                            </h3>
                            
                                <h4 class="mb-20">Manolis Pitsikalis,
                                Alexander Artikis</h4>
                            

                            <p class="justifyAlignment">In present times, where the shipping industry has an important
                                role
                                in the global
                                trade, there is an increased need for safer and more secure shipping. Maritime
                                Monitoring systems allow the real-time detection of dangerous, suspicious and
                                illegal vessel activities. We demonstrate such a system, that uses the Run-Time
                                Event Calculus, a composite event recognition system with formal, declarative
                                semantics. All the activities we demonstrate were detected using real-world
                                maritime data and contextual geographical information.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332519">A Demonstration
                                of Striim A
                                Streaming Integration and Intelligence Platform</a></h3>
                            
                                <h4 class="mb-20">Alok Pareek,
                                Bohan Zhang,
                                Bhushan Khaladkar</h4>
                            

                            <p class="justifyAlignment">Today's data-driven applications need to process, analyze and
                                act on
                                real-time
                                data as it arrives. The massive amount of data is continuously generated from
                                multiple sources and arrives in a streaming fashion with high volume and high
                                velocity, which makes it hard to process and analyze in real time. We introduce
                                Striim, a distributed streaming platform that enables real-time integration and
                                intelligence. Striim provides high-throughput, low-latency event processing. It
                                can ingest streaming data from multiple sources, process data with SQL-like
                                query language, analyze data with sophisticated machine learning models, write
                                data into a variety of targets, and visualize data for real-time decision
                                making. In this demonstration, we showcase Striim's ability to collect,
                                integrate, process, analyze and visualize large streaming data in real time.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332505">Service Function
                                Chaining
                                Across OpenStack and Kubernetes Domains</a></h3>
                            
                                <h4 class="mb-20">Hadi Razzaghi Kouchaksaraei,
                                Holger Karl</h4>
                            

                            <p class="justifyAlignment">Remarkable advantages of Containers (CNs) over Virtual Machines
                                (VMs) such as
                                lower overhead and faster startup has gained the attention of Communication
                                Service Providers (CSPs) as using CNs for providing Virtual Network Functions
                                (VNFs) can save costs while increasing the service agility. However, as it is
                                not feasible to realise all types of VNFs in CNs, the coexistence of VMs and CNs
                                is proposed. To put VMs and CNs together, an orchestration framework that can
                                chain services across distributed and heterogeneous domains is required. To this
                                end, we implemented a framework by extending and consolidating state-of-the-art
                                tools and technologies originated from Network Function Virtualization (NFV),
                                Software-defined Networking (SDN) and cloud computing environments. This
                                framework chains services provisioned across Kubernetes and OpenStack domains.
                                During the demo, we deploy a service consist of CN- and VM-based VNFs to
                                demonstrate different features provided by our framework.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332508">Modeling the
                                Software
                                Execution
                                of CEP in DCEP-Sim</a></h3>
                            
                                <h4 class="mb-20">Espen Volnes,
                                Stein Kristiansen,
                                Thomas Plagemann,
                                Vera Goebel,
                                Morten Lindeberg</h4>
                            

                            <p class="justifyAlignment">DCEP-Sim facilitates simulation of distributed CEP where the
                                latency
                                and
                                bandwidth limitations in the network are well reflected, but it currently lacks
                                models to simulate the temporal behavior of event processing. In this
                                demonstration, we use a modeling methodology to model the software execution of
                                a CEP system called T-Rex. We instrument and trace T-Rex to parameterize a
                                software execution model that is integrated into DCEP-Sim. Furthermore, we use
                                this instance of DCEP-Sim to run simulations and see how significant the
                                processing delay introduced by the model is compared to the transmission
                                delay.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332520">On the Need for
                                Distributed
                                Complex Event Processing with Multiple Sinks</a></h3>
                            
                                <h4 class="mb-20">Samira Akili</h4>
                            

                            <p class="justifyAlignment">Distributed complex event processing evaluates CEP-queries over
                                data
                                produced by
                                geographically distributed sources. To cope with bandwith restrictions, it is
                                common to employ in-network processing where the operators of a query are placed
                                at network nodes, especially those that act as data sources. While existing
                                operator placement algorithms handle distributed sources, query results are
                                gathered at one designated node -- the sink. We argue that such single-sink
                                solutions are not applicable for non-hierarchical systems, in which multiple
                                nodes need to be informed about query results. Also, in compositional
                                applications, where the result of one query is the input to another query,
                                having a single sink enforces centralisation. Using a real-world application
                                scenario, we illustrate the need for a novel DCEP approach with a multi-sink
                                operator placement. Furthermore, we elaborate on the requirements to be
                                incorporated by a DCEP approach targeting highly decentralized systems.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332518">Temporal Pattern
                                Recognition
                                in
                                Large Scale Graphs</a></h3>
                            
                                <h4 class="mb-20">Hassan Nazeer Chaudhry,
                                Alessandro Margara,
                                Matteo Rossi</h4>
                            

                            <p class="justifyAlignment">Many application domains involve monitoring the temporal
                                evolution
                                of large-scale
                                graph data structures. Unfortunately, this task is not well supported by modern
                                programming paradigms and frameworks for large-scale data processing. This paper
                                presents ongoing work on the implementation of FlowGraph, a framework to
                                recognize temporal patterns over properties of large-scale graphs. FlowGraph
                                combines the programming paradigm of traditional graph computation frameworks
                                with the temporal pattern detection capabilities of Complex Event Recognition
                                (CER) systems. In a nutshell, FlowGraph distributes the graph data structure
                                across multiple nodes that also contribute to the computation and store partial
                                results for pattern detection. It exploits temporal properties to defer as much
                                as possible expensive computations, to sustain a high rate of changes.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332506">Benchmarking
                                Financial Data
                                Feed Systems</a></h3>
                            
                                <h4 class="mb-20">Manuel Coenen,
                                Christoph Wagner,
                                Alexander Echler,
                                Sebastian Frischbier</h4>
                            

                            <p class="justifyAlignment">Data-driven solutions for the investment industry require
                                event-based backend
                                systems to process high-volume financial data feeds with low latency, high
                                throughput, and guaranteed delivery modes.</p>
                            <p class="justifyAlignment">At vwd we process an average of 18 billion incoming event
                                notifications from 500+
                                data sources for 30 million symbols per day and peak rates of 1+ million
                                notifications per second using custom-built platforms that keep audit logs of
                                every event.</p>
                            <p class="justifyAlignment">We currently assess modern open source event-processing
                                platforms
                                such as Kafka,
                                NATS, Redis, Flink or Storm for the use in our ticker plant to reduce the
                                maintenance effort for cross-cutting concerns and leverage hybrid deployment
                                models. For comparability and repeatability we benchmark candidates with a
                                standardized workload we derived from our real data feeds.</p>
                            <p class="justifyAlignment">We have enhanced an existing light-weight open source
                                benchmarking
                                tool in its
                                processing, logging, and reporting capabilities to cope with our workloads. The
                                resulting tool wrench can simulate workloads or replay snapshots in volume and
                                dynamics like those we process in our ticker plant. We provide the tool as open
                                source.</p>
                            <p class="justifyAlignment">As part of ongoing work we contribute details on (a) our
                                workload
                                and
                                requirements for benchmarking candidate platforms for financial feed processing;
                                (b) the current state of the tool wrench.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332513">A Real-World
                                Distributed
                                Infrastructure for Processing Financial Data at Scale</a></h3>
                            
                                <h4 class="mb-20">Sebastian Frischbier,
                                Mario Paic,
                                Alexander Echler,
                                Christian Roth</h4>
                            

                            <p class="justifyAlignment">Financial markets are event- and data-driven to an extremely
                                high
                                degree. For
                                making decisions and triggering actions stakeholders require notifications about
                                significant events and reliable background information that meet their
                                individual requirements in terms of timeliness, accuracy, and completeness. As
                                one of Europe's leading providers of financial data and regulatory solutions
                                vwd: processes an average of 18 billion event notifications from 500+ data
                                sources for 30 million symbols per day. Our large-scale distributed event-based
                                systems handle daily peak rates of 1+ million event notifications per second and
                                additional load generated by singular pivotal events with global impact.</p>
                            <p class="justifyAlignment">In this poster we give practical insights into our IT systems.
                                We
                                outline the
                                infrastructure we operate and the event-driven architecture we apply at vwd. In
                                particular we showcase the (geo)distributed publish/subscribe broker network we
                                operate across locations and countries to provide market data to our customers
                                with varying quality of information (QoI) properties.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332511">Generating
                                Reproducible
                                Out-of-Order Data Streams</a></h3>
                            
                                <h4 class="mb-20">Philipp M. Grulich,
                                Jonas Traub,
                                Sebastian Breß,
                                Asterios Katsifodimos,
                                Volker Markl,
                                Tilmann Rabl</h4>
                            

                            <p class="justifyAlignment">Evaluating modern stream processing systems in a reproducible
                                manner
                                requires
                                data streams with different data distributions, data rates, and real-world
                                characteristics such as delayed and out-of-order tuples. In this paper, we
                                present an open source stream generator which generates reproducible and
                                deterministic out-of-order streams based on real data files, simulating
                                arbitrary fractions of out-of-order tuples and their respective delays.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332516">Mimir - Streaming
                                Operators
                                Classification with Artificial Neural Networks</a></h3>
                            
                                <h4 class="mb-20">Victor Gustafsson,
                                Hampus Nilsson,
                                Karl Bäckström,
                                Marina Papatriantafilou,
                                Vincenzo Gulisano</h4>
                            

                            <p class="justifyAlignment">Streaming applications are used for analysing large volumes of
                                continuous data.
                                Achieving efficiency and effectiveness in data streaming imply challenges that
                                gen all the more important when different parties (i) define applications'
                                semantics, (ii) choose the stream Processing Engine (SPE) to use, and (iii)
                                provide the processing infrastructure (e.g., cloud or fog), and when one party's
                                decisions (e.g., how to deploy applications or when to trigger adaptive
                                reconfigurations) depend on information held by a distinct one (and possibly
                                hard to retrieve). In this context, machine learning can bridge the involved
                                parties (e.g., SPEs and cloud providers) by offering tools that learn from the
                                behavior of streaming applications and help take decisions.</p>
                            <p class="justifyAlignment">Such a tool, the focus of our ongoing work, can be used to learn
                                which operators
                                are run by a streaming application running in a certain SPE, without relying on
                                the SPE itself to provide such information. More concretely, to classify the
                                type of operator based on a desired level of granularity (from a coarse-grained
                                characterization into stateless/stateful, to a fine-grained operator
                                classification) based on general application-related metrics. As an example
                                application, this tool could help a Cloud provider decide which infrastructure
                                to assign to a certain streaming application (run by a certain SPE), based on
                                the type (and thus cost) of its operators.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332515">Location Privacy
                                in
                                Heterogeneous Vehicular Networks</a></h3>
                            
                                <h4 class="mb-20">Tobias Meuser,
                                Daniel Bischoff,
                                Ralf Steinmetz</h4>
                            

                            <p class="justifyAlignment">Vehicle exchange Floating Car Data (FCD) to increase their
                                awareness
                                beyond their
                                local perception. For this purpose, the context-sensitive FCD is commonly
                                distributed using the cellular network. To receive FCD via the cellular network,
                                the vehicles share their current context (often location) with a backend.</p>
                            <p class="justifyAlignment">This permanent and accurate observation of the vehicle's context
                                interferes with
                                the privacy of the occupants. In this work, we use obfuscation to protect the
                                location privacy of the occupants. For this purpose, we adopt the precision of
                                the context monitoring of the vehicle to the privacy needs of the occupants. As
                                unnecessary FCD is transmitted to the vehicle, this imprecision reduces the
                                share of useful FCD, which might lead to additional bandwidth consumption. We
                                compensate for this additional consumption by filtering FCD with low impact for
                                the vehicle and simultaneously relying on less-privacy-aware vehicles to provide
                                FCD via local communication channels like Wifi.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332509">On Evaluating the
                                Impact of
                                Changes in IoT Data Streams Rate over Query Window Configurations</a></h3>
                            
                                <h4 class="mb-20">Radhya Sahal,
                                John G. Breslin,
                                Muhammad Intizar Ali</h4>
                            

                            <p class="justifyAlignment">With the ever increasing number of IoT devices getting
                                connected, an
                                enormous
                                amount of streaming data is being produced with very high velocity. In order to
                                process these large number of data streams, a variety of stream processing
                                platforms and query engines are emerging. In the stream query processing, an
                                infinite data stream is divided into small chunks of finite data using a window
                                operator. Window size and its type play an important role in the performance of
                                any stream query engine. Due to the dynamic nature of IoT, data stream rate
                                fluctuates very often, thus impeding the performance of query engines. In this
                                work, we investigated the impact of any changes in data stream rates over the
                                performance of a distributed query engine (e.g. Flink -
                                https://flink.apache.org/). Our evaluation results indicate a direct impact of
                                any changes in stream rate and window size over the performance of the engines.
                                We propose an adaptive and dynamic query window size and type selector to
                                improve the resilience of query processing engines. We consider several
                                characteristics of input data streams, application workload, and resource
                                constraints and proposes an optimal stream query window size and type for stream
                                query execution.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332514">Reproducible and
                                Reliable
                                Distributed Classification of Text Streams</a></h3>
                            
                                <h4 class="mb-20">Artem Trofimov,
                                Mikhail Shavkunov,
                                Sergey Reznick,
                                Nikita Sokolov,
                                Mikhail Yutman,
                                Igor E. Kuralenok,
                                Boris Novikov</h4>
                            

                            <p class="justifyAlignment">Large-scale classification of text streams is an essential
                                problem
                                that is hard
                                to solve. Batch processing systems are scalable and proved their effectiveness
                                for machine learning but do not provide low latency. On the other hand,
                                state-of-the-art distributed stream processing systems are able to achieve low
                                latency but do not support the same level of fault tolerance and determinism. In
                                this work, we discuss how the distributed streaming computational model and
                                fault tolerance mechanisms can affect the correctness of text classification
                                data flow. We also propose solutions that can mitigate the revealed
                                pitfalls.</p>

                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332521">Incremental
                                Reasoning for
                                Fleet
                                Management</a></h3>
                            
                                <h4 class="mb-20">Efthimis Tsilionis,
                                Alexander Artikis,
                                    Georgios Paliouras</h4>

                            <p class="justifyAlignment">We propose RTECinc, an incremental version of RTEC, a composite
                                event recognition
                                engine with formal, declarative semantics, that has been shown to scale to
                                several real-world data streams. RTEC deals with delayed arrival of events by
                                computing at each query time everything from scratch. This is often not
                                efficient since it results to redundant computations. Instead, RTECinc deals
                                with delays in a more efficient way, by updating only the affected events. We
                                compare RTECinc and RTEC experimentally using a real-world dataset with position
                                signals of vehicles.</p>
                        </div>
                    </div>

                    <div class="section-top-border" style="padding:20px 0px;">
                        <div class="single-defination">
                            <h2 class="mb-20">SESSION: Doctoral Symposium</h2>
                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332302">Leaderless
                                Replication and
                                Balance Management of Unordered SMS Messages</a></h3>

                            <h4 class="mb-20">Daniel Brahneborg</h4>

                            <p class="justifyAlignment">Mobile text messages (SMS) are often used for sending
                                authentication
                                codes,
                                meeting reminders and other messages which need to be forwarded from
                                applications to various mobile network operators, to eventually be delivered to
                                the users' mobile phones. To avoid message loss in the case of server failures,
                                each message needs to be stored on one or more of the other servers until it has
                                been successfully delivered. When this replication is implemented using a
                                traditional clustered database (e.g., FairCom CTree, MongoDB, and MySQL), we
                                achieve an unacceptably low throughput of at most a few hundred messages per
                                second (MPS) getting stored, marked as being processed by a single server, and
                                then finally deleted.</p>
                            <p class="justifyAlignment">In order to improve upon this throughput, we will combine and
                                extend
                                ideas from
                                existing work in the design and implementation of a new protocol better suited
                                for this use case. An early version of such a protocol has been able to reach a
                                throughput of about 14 000 MPS.</p>
                            <p class="justifyAlignment">The existing replication protocols use a general system model
                                which
                                covers most
                                common situations. By carefully scrutinizing this model and discarding
                                assumptions not applicable in our particular situation, e.g. a consistent global
                                order, we should be able to achieve a significantly higher throughput.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332303">FlowGraph:
                                Distributed temporal
                                pattern detection over dynamically evolving graphs</a></h3>

                            <h4 class="mb-20">Hassan Nazeer Chaudhry</h4>


                            <p class="justifyAlignment">Temporally evolving graphs are an indispensable requisite of
                                modern-day big data
                                processing pipelines. Existing graph processing systems mostly focus on static
                                graphs and lack the essential support for pattern detection and event processing
                                in graph-shaped data. On the other hand, stream processing systems support event
                                and pattern detection, but they are inadequate for graph processing. This work
                                lies at the intersection of the graph and stream processing domains with the
                                following objectives: (i) It introduces the syntax of a language for the
                                detection of temporal patterns in large-scale graphs. (ii) It presents a novel
                                data structure called distributed label store (DLS) to efficiently store graph
                                computation results and discover temporal patterns within them. The proposed
                                system, called FlowGraph, unifies graph-shaped data with stream processing by
                                observing graph changes as a stream flowing into the system. It provides an API
                                to handle temporal patterns that predicate on the results of graph computations
                                with traditional graph computations.</p>


                            <h3 class="mb-20"><a title="Full Citation in the ACM Digital Library"
                                                 referrerpolicy="no-referrer-when-downgrade"
                                                 href="https://dl.acm.org/doi/10.1145/3328905.3332304">Self-Adaptive
                                Data
                                Stream
                                Processing in Geo-Distributed Computing Environments</a></h3>

                            <h4 class="mb-20">Gabriele Russo Russo</h4>

                            <p class="justifyAlignment">An ever increasing number of services requires real-time
                                analysis of
                                collected
                                data streams. Emerging Fog/Edge computing platforms are appealing for such
                                latency-sensitive applications, encouraging the deployment of Data Stream
                                Processing (DSP) systems in geo-distributed environments. However, the highly
                                dynamic nature of these infrastructures poses challenges on how to satisfy the
                                Quality of Service requirements of both the application and the infrastructure
                                providers.</p>
                            <p class="justifyAlignment">In this doctoral work we investigate how DSP systems can face
                                the
                                dynamicity of
                                workloads and computing environments by self-adapting their deployment and
                                behavior at run-time. Targeting geo-distributed infrastructures, we specifically
                                search for decentralized solutions, and propose a framework for organizing
                                adaptation using a hierarchical control approach. Focusing on application
                                elasticity, we equip the framework with decentralized policies based on
                                reinforcement learning. We extend our solution to consider multi-level
                                elasticity, and heterogeneous computing resources. In the ongoing research work,
                                we aim to face the challenges associated with mobility of users and computing
                                resources, exploring complementary adaptation mechanisms.</p>

                        </div>
                    </div>

                </div>
                <div class="col-lg-3">
                    <div class="single-defination">
                        <img src="img/combined_sideBySide.png" widthalt="" class="img-fluid">
                        <p class="justifyAlignment mt-15" style="font-size: 12px;"><a href="http://sigmod2019.org/"
                                                                                      target="_blank">
                            DEBS will be held back-to-back
                            with SIGMOD 2019 in Europe.
                        </a></p>
                    </div>
                    <div class="single-defination mt-30">
                        <h4 class="mb-20">Important Dates</h4>
                        <div class="row">
                            <div class="table-wrap col-lg-12" style="font-size: 12px;">
                                <table class="schdule-table table table-bordered">
                                    <col width="66%">
                                    <col width="34%">
                                    <tbody>
                                    <tr>
                                        <td>Abstract submission for research track</td>
                                        <td>
                                            <del><span>February 19th</span></del>
                                            <strong>March 8th, 2019</strong></td>
                                    </tr>
                                    <tr>
                                        <td>Research and Industry paper submission</td>
                                        <td>
                                            <del><span>February 26th</span></del>
                                            <strong>March 8th, 2019</strong></td>
                                    </tr>
                                    <tr>
                                        <td>Tutorial proposal submission</td>
                                        <td>
                                            <del><span>March 22nd</span></del>
                                            <strong>April 5, 2019</strong></td>
                                    </tr>
                                    <tr>
                                        <td>Grand challenge solution submission</td>
                                        <td>
                                            <del><span>April 7th</span></del>
                                            <strong>April 22nd, 2019</strong></td>
                                    </tr>
                                    <tr>
                                        <td>Author notification research and industry track</td>
                                        <td>
                                            <del><span>April 9th</span></del>
                                            <strong>April 19th, 2019</strong></td>
                                    </tr>
                                    <tr>
                                        <td>Poster, demo & doctoral symposium submission</td>
                                        <td><strong>
                                            <del>April 22nd</del>
                                            May 3rd, 2019</strong></td>
                                    </tr>
                                    <tr>
                                        <td>Early registration</td>
                                        <td><strong>May 31st, 2019</strong></td>
                                    </tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                    </div>
                    <div class="single-defination mt-30">
                        <h4 class="mb-20">Social Media</h4>
                        <div class="footer-social d-flex align-items-center" style="padding-left:10px;">
                            <a href="https://www.facebook.com/ACM.DEBS/" target="_blank"><i class="fa fa-facebook"></i></a>
                            <a href="https://twitter.com/ACM_DEBS" target="_blank"><i class="fa fa-twitter"></i></a>
                            <a href="https://www.linkedin.com/groups/4747505/" target="_blank"><i
                                    class="fa fa-linkedin"></i></a>
                        </div>
                        <div class="table-wrap">
                            <table class="schdule-table table table-bordered">
                                <tbody>
                                <tr>
                                    <a class="twitter-timeline"
                                       href="https://twitter.com/acm_debs?lang=en" data-height="400"
                                       data-chrome="nofooter"
                                       data-link-color="#55acee"
                                       data-border-color="#DCDCDC">A Twitter List by TwitterDev</a>
                                    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8">
                                    </script>
                                </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<section class="brand-area pb-40">
    <div class="container">
        <h3 class="mb-20">Sponsors</h3>
        <div class="row logo-wrap">
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" src="img/ACM_sponsor.jpg"></div>
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" src="img/SIGMOD_sponsor.jpg"></div>
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" src="img/SIGSOFT_sponsor.jpg"></div>
        </div>
    </div>
</section>
<!-- Begin sponsor area -->
<!-- Begin Supporters area -->
<!--<section class="brand-area pb-40">
    <div class="container">
        <h3 class="mb-20">Supporters</h3>
        <div class="row logo-wrap">
            <img class="d-block mx-auto"  style="width:15%; height:10%;"src="img/INDI_sponsor.jpg">
            <img class="d-block mx-auto" style="width: 25%; height:10%;" src="img/MAKI_Supporter.png">
            <img class="d-block mx-auto" style="width: 20%; height:10%;" src="img/tud_logo.jpg">
        </div>
        <div class="row logo-wrap mt-10">
            <img class="d-block mx-auto" style="width: 20%; height:10%;" src="img/axxessio_Supporter.png">
            <img class="d-block mx-auto"  style="width:15%; height:10%;"src="img/crossing_supporters.jpg">
            <img class="d-block mx-auto" style="width: 15%; height:10%;" src="img/SAP_Supporter.png">
        </div>
    </div>
</section>-->
<!-- End Supporters area -->
<!-- Begin Supporters area -->
<section class="brand-area pb-40">
    <div class="container">
        <h3 class="mb-20">Supporters</h3>
        <div class="row logo-wrap">
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" style="width:60%;" src="img/INDI_sponsor.jpg"></div>
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" style="width:70%;" src="img/MAKI_Supporter.png"></div>
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" style="width:70%;" src="img/tud_logo.jpg"></div>
        </div>
        <div class="row logo-wrap mt-10">
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" style="width: 70%;" src="img/axxessio_Supporter.png"></div>
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" style="width:50%;" src="img/crossing_supporters.jpg"></div>
            <div class="col-md-4 mt-10">
                <img class="d-block mx-auto" style="width: 50%;" src="img/SAP_Supporter.png"></div>
        </div>
    </div>
</section>
<!-- End Supporters area -->

<!-- start footer Area -->
<footer class="footer-area section-gap" style="padding-top: 20px; padding-bottom: 20px;">
    <div class="container">
        <div class="row">
            <div class="col-lg-9 col-md-6 col-sm-6">
                <div class="single-footer-widget">
                    <p class="footer-text">
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | TU Darmstadt
                    </p>
                    <p class="footer-text">
                        <a href="https://www.kom.tu-darmstadt.de/kom-multimedia-communications-lab/people/staff/boris-koldehofe/"
                           target="_blank">Contact</a> |
                        <a href="https://www.kom.tu-darmstadt.de/impressum/" target="_blank">Imprints</a>
                </div>
            </div>
            <div class="col-lg-3 col-md-6 col-sm-6 social-widget">
                <div class="single-footer-widget">
                    <h6>Follow Us</h6>
                    <p class="justifyAlignment">DEBS on Social Media</p>
                    <div class="footer-social d-flex align-items-center">
                        <a href="https://www.facebook.com/ACM.DEBS/" target="_blank"><i class="fa fa-facebook"></i></a>
                        <a href="https://twitter.com/ACM_DEBS" target="_blank"><i class="fa fa-twitter"></i></a>
                        <a href="https://www.linkedin.com/groups/4747505/" target="_blank"><i
                                class="fa fa-linkedin"></i></a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</footer>
<!-- End footer Area -->

<script src="js/vendor/jquery-2.2.4.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
        integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
        crossorigin="anonymous"></script>
<script src="js/vendor/bootstrap.min.js"></script>
<script type="text/javascript"
        src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBhOdIF3Y9382fqJYt5I_sswSrEw5eihAA"></script>
<script src="js/easing.min.js"></script>
<script src="js/hoverIntent.js"></script>
<script src="js/superfish.min.js"></script>
<script src="js/jquery.ajaxchimp.min.js"></script>
<script src="js/jquery.magnific-popup.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.nice-select.min.js"></script>
<script src="js/parallax.min.js"></script>
<script src="js/mail-script.js"></script>
<script src="js/main.js"></script>
</body>
</html>



